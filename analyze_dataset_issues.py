#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –∫–∞—Ä—Ç –ë–µ—Ä—Å–µ—Ä–∫
"""

import os
import pandas as pd
import numpy as np
from collections import Counter
import json
from data_preparation import BerserkCardDataset

def analyze_dataset_structure():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ —Å –∫–∞—Ä—Ç–∞–º–∏"""
    print("=== –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –î–ê–¢–ê–°–ï–¢–ê ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞–ø–∫–∏
    folders_to_check = ['./cards', './cards_augmented']
    
    for folder in folders_to_check:
        if os.path.exists(folder):
            print(f"\nüìÅ –ü–∞–ø–∫–∞: {folder}")
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ
            root_files = [f for f in os.listdir(folder) 
                         if f.lower().endswith(('.webp', '.jpg', '.jpeg', '.png'))]
            print(f"   –§–∞–π–ª–æ–≤ –≤ –∫–æ—Ä–Ω–µ: {len(root_files)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–ø–∞–ø–∫–∏
            subdirs = [d for d in os.listdir(folder) 
                      if os.path.isdir(os.path.join(folder, d))]
            
            if subdirs:
                print(f"   –ü–æ–¥–ø–∞–ø–æ–∫: {len(subdirs)}")
                total_subdir_files = 0
                
                for subdir in subdirs[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    subdir_path = os.path.join(folder, subdir)
                    subdir_files = [f for f in os.listdir(subdir_path) 
                                   if f.lower().endswith(('.webp', '.jpg', '.jpeg', '.png'))]
                    total_subdir_files += len(subdir_files)
                    print(f"     {subdir}: {len(subdir_files)} —Ñ–∞–π–ª–æ–≤")
                
                if len(subdirs) > 10:
                    print(f"     ... –∏ –µ—â–µ {len(subdirs) - 10} –ø–æ–¥–ø–∞–ø–æ–∫")
                    
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø–∞–ø–∫–∞—Ö
                    for subdir in subdirs[10:]:
                        subdir_path = os.path.join(folder, subdir)
                        subdir_files = [f for f in os.listdir(subdir_path) 
                                       if f.lower().endswith(('.webp', '.jpg', '.jpeg', '.png'))]
                        total_subdir_files += len(subdir_files)
                
                print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö: {total_subdir_files}")
                print(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {len(root_files) + total_subdir_files}")
            else:
                print(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {len(root_files)}")
        else:
            print(f"\n‚ùå –ü–∞–ø–∫–∞ {folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

def analyze_csv_files():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç CSV —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏"""
    print("\n=== –ê–ù–ê–õ–ò–ó CSV –§–ê–ô–õ–û–í ===")
    
    csv_files = ['cards_dataset.csv', 'augmented_cards_dataset.csv']
    
    for csv_file in csv_files:
        if os.path.exists(csv_file):
            print(f"\nüìÑ –§–∞–π–ª: {csv_file}")
            df = pd.read_csv(csv_file)
            
            print(f"   –°—Ç—Ä–æ–∫ –≤ CSV: {len(df)}")
            print(f"   –°—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")
            
            if 'card_id_encoded' in df.columns:
                unique_classes = df['card_id_encoded'].nunique()
                max_class = df['card_id_encoded'].max()
                min_class = df['card_id_encoded'].min()
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤: {unique_classes}")
                print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –∫–ª–∞—Å—Å–æ–≤: {min_class} - {max_class}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤
                all_classes = set(range(min_class, max_class + 1))
                actual_classes = set(df['card_id_encoded'].unique())
                missing_classes = all_classes - actual_classes
                
                if missing_classes:
                    print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {sorted(missing_classes)}")
                else:
                    print(f"   ‚úÖ –ù—É–º–µ—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º
            if 'card_id' in df.columns:
                class_counts = df['card_id'].value_counts()
                print(f"   –ö–ª–∞—Å—Å–æ–≤ —Å 1 –ø—Ä–∏–º–µ—Ä–æ–º: {sum(class_counts == 1)}")
                print(f"   –ö–ª–∞—Å—Å–æ–≤ —Å 2-5 –ø—Ä–∏–º–µ—Ä–∞–º–∏: {sum((class_counts >= 2) & (class_counts <= 5))}")
                print(f"   –ö–ª–∞—Å—Å–æ–≤ —Å >5 –ø—Ä–∏–º–µ—Ä–∞–º–∏: {sum(class_counts > 5)}")
                print(f"   –ú–∞–∫—Å–∏–º—É–º –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–ª–∞—Å—Å–µ: {class_counts.max()}")
                print(f"   –ú–∏–Ω–∏–º—É–º –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–ª–∞—Å—Å–µ: {class_counts.min()}")
        else:
            print(f"\n‚ùå –§–∞–π–ª {csv_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")

def analyze_saved_arrays():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã –¥–∞–Ω–Ω—ã—Ö"""
    print("\n=== –ê–ù–ê–õ–ò–ó –°–û–•–†–ê–ù–ï–ù–ù–´–• –ú–ê–°–°–ò–í–û–í ===")
    
    if os.path.exists('X_data.npy') and os.path.exists('y_data.npy'):
        print("\nüìä –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã...")
        
        X = np.load('X_data.npy')
        y = np.load('y_data.npy')
        
        print(f"   –§–æ—Ä–º–∞ X: {X.shape}")
        print(f"   –§–æ—Ä–º–∞ y: {y.shape}")
        print(f"   –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö X: {X.dtype}")
        print(f"   –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö y: {y.dtype}")
        
        unique_classes = len(np.unique(y))
        max_class = np.max(y)
        min_class = np.min(y)
        
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤: {unique_classes}")
        print(f"   –î–∏–∞–ø–∞–∑–æ–Ω –∫–ª–∞—Å—Å–æ–≤: {min_class} - {max_class}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –Ω—É–º–µ—Ä–∞—Ü–∏–∏
        all_classes = set(range(min_class, max_class + 1))
        actual_classes = set(y)
        missing_classes = all_classes - actual_classes
        
        if missing_classes:
            print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {sorted(missing_classes)}")
            print(f"   ‚ùó –≠—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏!")
        else:
            print(f"   ‚úÖ –ù—É–º–µ—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
        class_counts = Counter(y)
        counts_distribution = Counter(class_counts.values())
        
        print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤:")
        for count, num_classes in sorted(counts_distribution.items()):
            print(f"     {count} –ø—Ä–∏–º–µ—Ä–æ–≤: {num_classes} –∫–ª–∞—Å—Å–æ–≤")
        
        return X, y
    else:
        print("\n‚ùå –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None, None

def check_label_encoders():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —ç–Ω–∫–æ–¥–µ—Ä—ã –º–µ—Ç–æ–∫"""
    print("\n=== –ê–ù–ê–õ–ò–ó –≠–ù–ö–û–î–ï–†–û–í –ú–ï–¢–û–ö ===")
    
    if os.path.exists('label_encoders.json'):
        print("\nüîß –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–Ω–∫–æ–¥–µ—Ä—ã...")
        
        with open('label_encoders.json', 'r', encoding='utf-8') as f:
            encoders = json.load(f)
        
        for encoder_name, encoder_data in encoders.items():
            classes = encoder_data['classes']
            print(f"   {encoder_name}: {len(classes)} –∫–ª–∞—Å—Å–æ–≤")
            
            if encoder_name == 'card_id':
                print(f"     –ü—Ä–∏–º–µ—Ä—ã –∫–ª–∞—Å—Å–æ–≤: {classes[:5]}...")
                print(f"     –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å: {len(classes) - 1}")
    else:
        print("\n‚ùå –§–∞–π–ª —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω")

def suggest_fixes():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å–ø–æ—Å–æ–±—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º"""
    print("\n=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Æ ===")
    
    print("\nüîß –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
    print("\n1. –ü—Ä–æ–±–ª–µ–º–∞ —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
    print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏")
    print("   - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    print("   - –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python data_augmentation.py")
    
    print("\n2. –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏:")
    print("   - –ü–µ—Ä–µ—Å–æ–∑–¥–∞–π—Ç–µ —ç–Ω–∫–æ–¥–µ—Ä—ã –º–µ—Ç–æ–∫")
    print("   - –£–¥–∞–ª–∏—Ç–µ —Ñ–∞–π–ª—ã X_data.npy, y_data.npy –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–π—Ç–µ –∏—Ö")
    print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    
    print("\n3. –ü—Ä–æ–±–ª–µ–º–∞ —Å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ–º –∫–ª–∞—Å—Å–æ–≤:")
    print("   - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∫–ª–∞—Å—Å—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ")
    print("   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ stratified split –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
    print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –Ω—É–º–µ—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0")
    
    print("\n4. –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:")
    print("   # –û—á–∏—Å—Ç–∫–∞ –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    print("   rm X_data.npy y_data.npy label_encoders.json")
    print("   python data_preparation.py")
    print("   python train_model.py")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú –° –î–ê–¢–ê–°–ï–¢–û–ú –ö–ê–†–¢ –ë–ï–†–°–ï–†–ö")
    print("=" * 60)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    analyze_dataset_structure()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º CSV —Ñ–∞–π–ª—ã
    analyze_csv_files()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã
    X, y = analyze_saved_arrays()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–Ω–∫–æ–¥–µ—Ä—ã
    check_label_encoders()
    
    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —Ä–µ—à–µ–Ω–∏—è
    suggest_fixes()
    
    print("\n" + "=" * 60)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ GPU –¥–ª—è TensorFlow
–ü–æ–º–æ–≥–∞–µ—Ç –≤—ã—è–≤–∏—Ç—å –ø—Ä–∏—á–∏–Ω—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º TensorFlow –Ω–µ –≤–∏–¥–∏—Ç –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É
"""

import sys
import platform
import subprocess
import os

def check_nvidia_driver():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏ –≤–µ—Ä—Å–∏—é –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA...")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º nvidia-smi
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            lines = result.stdout.split('\n')
            for line in lines:
                if 'Driver Version:' in line:
                    driver_version = line.split('Driver Version:')[1].split()[0]
                    print(f"‚úÖ –î—Ä–∞–π–≤–µ—Ä NVIDIA –Ω–∞–π–¥–µ–Ω: –≤–µ—Ä—Å–∏—è {driver_version}")
                    return True
            print("‚úÖ nvidia-smi —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –≤–µ—Ä—Å–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞")
            return True
    except FileNotFoundError:
        print("‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω - –¥—Ä–∞–π–≤–µ—Ä NVIDIA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    except subprocess.TimeoutExpired:
        print("‚ö†Ô∏è nvidia-smi –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç (–≤–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º—ã —Å –¥—Ä–∞–π–≤–µ—Ä–æ–º)")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ nvidia-smi: {e}")
        return False

def check_cuda_installation():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É CUDA"""
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    cuda_path = os.environ.get('CUDA_PATH')
    cuda_home = os.environ.get('CUDA_HOME')
    
    if cuda_path:
        print(f"‚úÖ CUDA_PATH –Ω–∞–π–¥–µ–Ω: {cuda_path}")
    elif cuda_home:
        print(f"‚úÖ CUDA_HOME –Ω–∞–π–¥–µ–Ω: {cuda_home}")
    else:
        print("‚ö†Ô∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º nvcc
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            for line in result.stdout.split('\n'):
                if 'release' in line.lower():
                    print(f"‚úÖ CUDA Compiler –Ω–∞–π–¥–µ–Ω: {line.strip()}")
                    return True
    except FileNotFoundError:
        print("‚ùå nvcc –Ω–µ –Ω–∞–π–¥–µ–Ω - CUDA Toolkit –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ nvcc: {e}")
        return False
    
    return False

def check_cudnn():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É cuDNN"""
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ cuDNN...")
    
    try:
        import tensorflow as tf
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –ª–∏ TensorFlow –Ω–∞–π—Ç–∏ cuDNN
        if hasattr(tf.config.experimental, 'list_physical_devices'):
            gpus = tf.config.experimental.list_physical_devices('GPU')
        else:
            gpus = tf.config.list_physical_devices('GPU')
            
        if gpus:
            print("‚úÖ TensorFlow –≤–∏–¥–∏—Ç GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")
            for i, gpu in enumerate(gpus):
                print(f"   GPU {i}: {gpu}")
            return True
        else:
            print("‚ùå TensorFlow –Ω–µ –≤–∏–¥–∏—Ç GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")
            return False
            
    except ImportError:
        print("‚ùå TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —á–µ—Ä–µ–∑ TensorFlow: {e}")
        return False

def check_tensorflow_gpu_support():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ GPU –≤ TensorFlow"""
    print("\nüîç –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ TensorFlow GPU...")
    
    try:
        import tensorflow as tf
        print(f"‚úÖ TensorFlow –≤–µ—Ä—Å–∏—è: {tf.__version__}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–±—Ä–∞–Ω –ª–∏ TensorFlow —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA
        if tf.test.is_built_with_cuda():
            print("‚úÖ TensorFlow —Å–æ–±—Ä–∞–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA")
        else:
            print("‚ùå TensorFlow —Å–æ–±—Ä–∞–Ω –ë–ï–ó –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ tensorflow-gpu –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ conda")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {len(gpus)}")
            
            for i, gpu in enumerate(gpus):
                print(f"   GPU {i}: {gpu.name}")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ GPU
                try:
                    details = tf.config.experimental.get_device_details(gpu)
                    if details:
                        print(f"      –î–µ—Ç–∞–ª–∏: {details}")
                except:
                    pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU
            try:
                with tf.device('/GPU:0'):
                    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
                    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
                    c = tf.matmul(a, b)
                print("‚úÖ GPU —É—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π")
                return True
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ GPU: {e}")
                return False
        else:
            print("‚ùå GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False
            
    except ImportError:
        print("‚ùå TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ TensorFlow: {e}")
        return False

def check_system_info():
    """–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ"""
    print("üíª –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ:")
    print(f"   –û–°: {platform.system()} {platform.release()}")
    print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {platform.machine()}")
    print(f"   Python: {sys.version}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º PATH
    path_dirs = os.environ.get('PATH', '').split(os.pathsep)
    cuda_in_path = any('cuda' in dir.lower() for dir in path_dirs)
    if cuda_in_path:
        print("‚úÖ CUDA –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ PATH")
    else:
        print("‚ö†Ô∏è CUDA –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ PATH")

def provide_solutions():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –¥–ª—è —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º"""
    print("\n" + "="*60)
    print("üí° –í–û–ó–ú–û–ñ–ù–´–ï –†–ï–®–ï–ù–ò–Ø:")
    print("\n1. üéÆ –ï—Å–ª–∏ —É –≤–∞—Å NVIDIA –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞:")
    print("   ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥—Ä–∞–π–≤–µ—Ä NVIDIA")
    print("   ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 11.8 –∏–ª–∏ 12.x)")
    print("   ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ cuDNN")
    print("   ‚Ä¢ –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ TensorFlow: pip install tensorflow[and-cuda]")
    
    print("\n2. üîß –ï—Å–ª–∏ —É –≤–∞—Å AMD –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞:")
    print("   ‚Ä¢ TensorFlow –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç AMD GPU –Ω–∞–ø—Ä—è–º—É—é")
    print("   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ TensorFlow —Å CPU (—á—Ç–æ –∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–µ–π—á–∞—Å)")
    print("   ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ROCm (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)")
    
    print("\n3. üíª –ï—Å–ª–∏ —É –≤–∞—Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥—Ä–∞—Ñ–∏–∫–∞ Intel:")
    print("   ‚Ä¢ TensorFlow –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Intel GPU")
    print("   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CPU –≤–µ—Ä—Å–∏—é (—á—Ç–æ –∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–µ–π—á–∞—Å)")
    
    print("\n4. üêç –ü—Ä–æ–±–ª–µ–º—ã —Å —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π TensorFlow:")
    print("   ‚Ä¢ pip uninstall tensorflow")
    print("   ‚Ä¢ pip install tensorflow[and-cuda]")
    print("   ‚Ä¢ –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ conda: conda install tensorflow-gpu")
    
    print("\n5. üîÑ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    print("   ‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ CUDA –≤ PATH")
    print("   ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA_PATH –∏ CUDA_HOME")
    print("   ‚Ä¢ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –∫–æ–º–ø—å—é—Ç–µ—Ä –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ CUDA")
    
    print("\n6. ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:")
    print("   ‚Ä¢ python gpu_diagnostic.py")
    print("   ‚Ä¢ python main.py check")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU –î–õ–Ø TENSORFLOW")
    print("="*60)
    
    check_system_info()
    print("\n" + "="*60)
    
    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    nvidia_ok = check_nvidia_driver()
    cuda_ok = check_cuda_installation()
    cudnn_ok = check_cudnn()
    tf_gpu_ok = check_tensorflow_gpu_support()
    
    print("\n" + "="*60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –°–¢–ê–¢–£–°:")
    
    if tf_gpu_ok:
        print("üéâ GPU —É—Å–ø–µ—à–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å TensorFlow!")
    else:
        print("‚ö†Ô∏è GPU –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å TensorFlow")
        print("\n–ü—Ä–æ–±–ª–µ–º—ã:")
        if not nvidia_ok:
            print("   ‚ùå –î—Ä–∞–π–≤–µ—Ä NVIDIA –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        if not cuda_ok:
            print("   ‚ùå CUDA Toolkit –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        if not cudnn_ok:
            print("   ‚ùå TensorFlow –Ω–µ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU")
        
        provide_solutions()
    
    print("\n" + "="*60)
    print("‚ÑπÔ∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –≤–º–µ—Å—Ç–æ GPU –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ")
    print("   –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞, –Ω–æ GPU —É—Å–∫–æ—Ä–∏—Ç –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.")

if __name__ == "__main__":
    main()